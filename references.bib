
@article{korinek_ai_nodate,
	title = {{AI} {Agents} for {Economic} {Research}},
	language = {en},
	author = {Korinek, Anton},
	keywords = {AI/ML in Econ},
	file = {Korinek - AI Agents for Economic Research.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Korinek - AI Agents for Economic Research.pdf:application/pdf},
}

@article{korinek_llms_nodate,
	title = {{LLMs} {Learn} to {Collaborate} and {Reason}: {December} 2024 {Update} to “{Generative} {AI} for {Economic} {Research}: {Use} {Cases} and {Implications} for {Economists},” {Published} in the {Journal} of {Economic} {Literature} 61(4)},
	language = {en},
	author = {Korinek, Anton},
	keywords = {AI/ML in Econ},
	file = {Korinek - LLMs Learn to Collaborate and Reason December 2024 Update to “Generative AI for Economic Research.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Korinek - LLMs Learn to Collaborate and Reason December 2024 Update to “Generative AI for Economic Research.pdf:application/pdf},
}

@article{korinek_generative_2023,
	title = {Generative {AI} for {Economic} {Research}: {Use} {Cases} and {Implications} for {Economists}},
	volume = {61},
	issn = {0022-0515},
	shorttitle = {Generative {AI} for {Economic} {Research}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jel.20231736},
	doi = {10.1257/jel.20231736},
	abstract = {Generative artificial intelligence (AI) has the potential to revolutionize research. I analyze how large language models (LLMs) such as ChatGPT can assist economists by describing dozens of use cases in six areas: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. I provide general instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of generative AI to automate micro-tasks. Moreover, these gains will grow as the performance of AI systems continues to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources associated with this paper explain how to get started and will provide regular updates on the latest capabilities of generative AI in economics. (JEL A11, C45, D83, I23, O33)},
	language = {en},
	number = {4},
	urldate = {2025-09-09},
	journal = {Journal of Economic Literature},
	author = {Korinek, Anton},
	month = dec,
	year = {2023},
	keywords = {AI/ML in Econ},
	pages = {1281--1317},
	file = {Korinek - 2023 - Generative AI for Economic Research Use Cases and Implications for Economists.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Korinek - 2023 - Generative AI for Economic Research Use Cases and Implications for Economists.pdf:application/pdf},
}

@article{mullainathan_machine_2017,
	title = {Machine {Learning}: {An} {Applied} {Econometric} {Approach}},
	volume = {31},
	issn = {0895-3309},
	shorttitle = {Machine {Learning}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.31.2.87},
	doi = {10.1257/jep.31.2.87},
	abstract = {Machines are increasingly doing “intelligent” things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied.},
	language = {en},
	number = {2},
	urldate = {2025-12-02},
	journal = {Journal of Economic Perspectives},
	author = {Mullainathan, Sendhil and Spiess, Jann},
	month = may,
	year = {2017},
	keywords = {AI/ML in Econ, Survey},
	pages = {87--106},
	file = {Mullainathan and Spiess - 2017 - Machine Learning An Applied Econometric Approach.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Mullainathan and Spiess - 2017 - Machine Learning An Applied Econometric Approach.pdf:application/pdf},
}

@article{varian_big_2014,
	title = {Big {Data}: {New} {Tricks} for {Econometrics}},
	volume = {28},
	issn = {0895-3309},
	shorttitle = {Big {Data}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.28.2.3},
	doi = {10.1257/jep.28.2.3},
	abstract = {Computers are now involved in many economic transactions and can capture data associated with these transactions, which can then be manipulated and analyzed. Conventional statistical and econometric techniques such as regression often work well, but there are issues unique to big datasets that may require different tools. First, the sheer size of the data involved may require more powerful data manipulation tools. Second, we may have more potential predictors than appropriate for estimation, so we need to do some kind of variable selection. Third, large datasets may allow for more flexible relationships than simple linear models. Machine learning techniques such as decision trees, support vector machines, neural nets, deep learning, and so on may allow for more effective ways to model complex relationships. In this essay, I will describe a few of these tools for manipulating and analyzing big data. I believe that these methods have a lot to offer and should be more widely known and used by economists.},
	language = {en},
	number = {2},
	urldate = {2025-12-02},
	journal = {Journal of Economic Perspectives},
	author = {Varian, Hal R.},
	month = may,
	year = {2014},
	keywords = {AI/ML in Econ, Survey},
	pages = {3--28},
	file = {Varian - 2014 - Big Data New Tricks for Econometrics.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Varian - 2014 - Big Data New Tricks for Econometrics.pdf:application/pdf},
}

@article{athey_state_2017,
	title = {The {State} of {Applied} {Econometrics}: {Causality} and {Policy} {Evaluation}},
	volume = {31},
	issn = {0895-3309},
	shorttitle = {The {State} of {Applied} {Econometrics}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.31.2.3},
	doi = {10.1257/jep.31.2.3},
	abstract = {In this paper, we discuss recent developments in econometrics that we view as important for empirical researchers working on policy evaluation questions. We focus on three main areas, in each case, highlighting recommendations for applied work. First, we discuss new research on identification strategies in program evaluation, with particular focus on synthetic control methods, regression discontinuity, external validity, and the causal interpretation of regression methods. Second, we discuss various forms of supplementary analyses, including placebo analyses as well as sensitivity and robustness analyses, intended to make the identification strategies more credible. Third, we discuss some implications of recent advances in machine learning methods for causal effects, including methods to adjust for differences between treated and control units in high-dimensional settings, and methods for identifying and estimating heterogenous treatment effects.},
	language = {en},
	number = {2},
	urldate = {2025-12-02},
	journal = {Journal of Economic Perspectives},
	author = {Athey, Susan and Imbens, Guido W.},
	month = may,
	year = {2017},
	keywords = {AI/ML in Econ, Survey},
	pages = {3--32},
	file = {Athey and Imbens - 2017 - The State of Applied Econometrics Causality and Policy Evaluation.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Athey and Imbens - 2017 - The State of Applied Econometrics Causality and Policy Evaluation.pdf:application/pdf},
}

@article{kleinberg_prediction_2015,
	title = {Prediction {Policy} {Problems}},
	volume = {105},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.p20151023},
	doi = {10.1257/aer.p20151023},
	abstract = {Most empirical policy work focuses on causal inference. We argue an important class of policy problems does not require causal inference but instead requires predictive inference. Solving these “prediction policy problems” requires more than simple regression techniques, since these are tuned to generating unbiased estimates of coefficients rather than minimizing prediction error. We argue that new developments in the field of “machine learning” are particularly useful for addressing these prediction problems. We use an example from health policy to illustrate the large potential social welfare gains from improved prediction.},
	language = {en},
	number = {5},
	urldate = {2025-12-02},
	journal = {American Economic Review},
	author = {Kleinberg, Jon and Ludwig, Jens and Mullainathan, Sendhil and Obermeyer, Ziad},
	month = may,
	year = {2015},
	pages = {491--495},
	file = {Kleinberg et al. - 2015 - Prediction Policy Problems.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Kleinberg et al. - 2015 - Prediction Policy Problems.pdf:application/pdf},
}

@article{belloni_high-dimensional_2014,
	title = {High-{Dimensional} {Methods} and {Inference} on {Structural} and {Treatment} {Effects}},
	volume = {28},
	issn = {0895-3309},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.28.2.29},
	doi = {10.1257/jep.28.2.29},
	abstract = {Data with a large number of variables relative to the sample size—“high-dimensional data”—are readily available and increasingly common in empirical economics. Highdimensional data arise through a combination of two phenomena. First, the data may be inherently high dimensional in that many different characteristics per observation are available. For example, the US Census collects information on hundreds of individual characteristics and scanner datasets record transaction-level data for households across a wide range of products. Second, even when the number of available variables is relatively small, researchers rarely know the exact functional form with which the small number of variables enter the model of interest. Researchers are thus faced with a large set of potential variables formed by different ways of interacting and transforming the underlying variables. This paper provides an overview of how innovations in “data mining” can be adapted and modified to provide high-quality inference about model parameters. Note that we use the term “data mining” in a modern sense which denotes a principled search for “true” predictive power that guards against false discovery and overfitting, does not erroneously equate in-sample fit to out-of-sample predictive ability, and accurately accounts for using the same data to examine many different hypotheses or models.},
	language = {en},
	number = {2},
	urldate = {2025-12-03},
	journal = {Journal of Economic Perspectives},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
	month = may,
	year = {2014},
	keywords = {AI/ML in Econ, Survey},
	pages = {29--50},
	file = {Belloni et al. - 2014 - High-Dimensional Methods and Inference on Structural and Treatment Effects.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Belloni et al. - 2014 - High-Dimensional Methods and Inference on Structural and Treatment Effects.pdf:application/pdf},
}

@article{chernozhukov_doubledebiased_2018,
	title = {Double/debiased machine learning for treatment and structural parameters},
	volume = {21},
	copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	issn = {1368-4221, 1368-423X},
	url = {https://academic.oup.com/ectj/article/21/1/C1/5056401},
	doi = {10.1111/ectj.12097},
	language = {en},
	number = {1},
	urldate = {2025-12-03},
	journal = {The Econometrics Journal},
	author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
	month = feb,
	year = {2018},
	keywords = {AI/ML in Econ},
	pages = {C1--C68},
	file = {Chernozhukov et al. - 2018 - Doubledebiased machine learning for treatment and structural parameters.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Chernozhukov et al. - 2018 - Doubledebiased machine learning for treatment and structural parameters.pdf:application/pdf},
}

@article{belloni_inference_2014,
	title = {Inference on {Treatment} {Effects} after {Selection} among {High}-{Dimensional} {Controls}},
	volume = {81},
	issn = {0034-6527, 1467-937X},
	url = {https://academic.oup.com/restud/article-lookup/doi/10.1093/restud/rdt044},
	doi = {10.1093/restud/rdt044},
	abstract = {We propose robust methods for inference about the effect of a treatment variable on a scalar outcome in the presence of very many regressors in a model with possibly non-Gaussian and heteroscedastic disturbances. We allow for the number of regressors to be larger than the sample size. To make informative inference feasible, we require the model to be approximately sparse; that is, we require that the effect of confounding factors can be controlled for up to a small approximation error by including a relatively small number of variables whose identities are unknown. The latter condition makes it possible to estimate the treatment effect by selecting approximately the right set of regressors. We develop a novel estimation and uniformly valid inference method for the treatment effect in this setting, called the “post-double-selection” method. The main attractive feature of our method is that it allows for imperfect selection of the controls and provides conﬁdence intervals that are valid uniformly across a large class of models. In contrast, standard post-model selection estimators fail to provide uniform inference even in simple cases with a small, ﬁxed number of controls. Thus, our method resolves the problem of uniform inference after model selection for a large, interesting class of models. We also present a generalization of our method to a fully heterogeneous model with a binary treatment variable. We illustrate the use of the developed methods with numerical simulations and an application that considers the effect of abortion on crime rates.},
	language = {en},
	number = {2},
	urldate = {2025-12-03},
	journal = {The Review of Economic Studies},
	author = {Belloni, A. and Chernozhukov, V. and Hansen, C.},
	month = apr,
	year = {2014},
	pages = {608--650},
	file = {Belloni et al. - 2014 - Inference on Treatment Effects after Selection among High-Dimensional Controls.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Belloni et al. - 2014 - Inference on Treatment Effects after Selection among High-Dimensional Controls.pdf:application/pdf},
}

@article{athey_machine_2019,
	title = {Machine {Learning} {Methods} {That} {Economists} {Should} {Know} {About}},
	volume = {11},
	issn = {1941-1383, 1941-1391},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-economics-080217-053433},
	doi = {10.1146/annurev-economics-080217-053433},
	abstract = {We discuss the relevance of the recent machine learning (ML) literature for economics and econometrics. First we discuss the differences in goals, methods, and settings between the ML literature and the traditional econometrics and statistics literatures. Then we discuss some specific methods from the ML literature that we view as important for empirical researchers in economics. These include supervised learning methods for regression and classification, unsupervised learning methods, and matrix completion methods. Finally, we highlight newly developed methods at the intersection of ML and econometrics that typically perform better than either off-the-shelf ML or more traditional econometric methods when applied to particular classes of problems, including causal inference for average treatment effects, optimal policy estimation, and estimation of the counterfactual effect of price changes in consumer choice models.},
	language = {en},
	number = {1},
	urldate = {2025-12-03},
	journal = {Annual Review of Economics},
	author = {Athey, Susan and Imbens, Guido W.},
	month = aug,
	year = {2019},
	keywords = {AI/ML in Econ, Survey},
	pages = {685--725},
	file = {Athey and Imbens - 2019 - Machine Learning Methods That Economists Should Know About.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Athey and Imbens - 2019 - Machine Learning Methods That Economists Should Know About.pdf:application/pdf},
}

@article{masini_machine_2023,
	title = {Machine learning advances for time series forecasting},
	volume = {37},
	issn = {0950-0804, 1467-6419},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/joes.12429},
	doi = {10.1111/joes.12429},
	abstract = {In this paper, we survey the most recent advances in supervised machine learning (ML) and highdimensional models for time-series forecasting. We consider both linear and nonlinear alternatives. Among the linear methods, we pay special attention to penalized regressions and ensemble of models. The nonlinear methods considered in the paper include shallow and deep neural networks, in their feedforward and recurrent versions, and tree-based methods, such as random forests and boosted trees. We also consider ensemble and hybrid models by combining ingredients from different alternatives. Tests for superior predictive ability are briefly reviewed. Finally, we discuss application of ML in economics and finance and provide an illustration with high-frequency financial data.},
	language = {en},
	number = {1},
	urldate = {2025-12-03},
	journal = {Journal of Economic Surveys},
	author = {Masini, Ricardo P. and Medeiros, Marcelo C. and Mendes, Eduardo F.},
	month = feb,
	year = {2023},
	keywords = {AI/ML in Econ, Survey},
	pages = {76--111},
	file = {Masini et al. - 2023 - Machine learning advances for time series forecasting.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Masini et al. - 2023 - Machine learning advances for time series forecasting.pdf:application/pdf},
}

@article{belloni_sparse_2012,
	title = {Sparse {Models} and {Methods} for {Optimal} {Instruments} {With} an {Application} to {Eminent} {Domain}},
	volume = {80},
	copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	issn = {0012-9682},
	url = {http://doi.wiley.com/10.3982/ECTA9626},
	doi = {10.3982/ECTA9626},
	language = {en},
	number = {6},
	urldate = {2025-12-03},
	journal = {Econometrica},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian and Chen, Daniel},
	year = {2012},
	pages = {2369--2429},
	file = {Belloni et al. - 2012 - Sparse Models and Methods for Optimal Instruments With an Application to Eminent Domain.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/2012 - Sparse Models and Methods for Optimal Instruments With an Application to Eminent Domain.pdf:application/pdf},
}


@article{leeb_can_2008,
	title = {{CAN} {ONE} {ESTIMATE} {THE} {UNCONDITIONAL} {DISTRIBUTION} {OF} {POST}-{MODEL}-{SELECTION} {ESTIMATORS}?},
	volume = {24},
	issn = {0266-4666, 1469-4360},
	url = {http://www.journals.cambridge.org/abstract_S0266466608080158},
	doi = {10.1017/S0266466608080158},
	language = {en},
	number = {02},
	urldate = {2025-12-04},
	journal = {Econometric Theory},
	author = {Leeb, Hannes and Pötscher, Benedikt M.},
	month = apr,
	year = {2008},
	file = {Leeb and Pötscher - 2008 - CAN ONE ESTIMATE THE UNCONDITIONAL DISTRIBUTION OF POST-MODEL-SELECTION ESTIMATORS.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Leeb and Pötscher - 2008 - CAN ONE ESTIMATE THE UNCONDITIONAL DISTRIBUTION OF POST-MODEL-SELECTION ESTIMATORS.pdf:application/pdf},
}

@article{leeb_guest_2008,
	title = {{GUEST} {EDITORS}' {EDITORIAL}: {RECENT} {DEVELOPMENTS} {IN} {MODEL} {SELECTION} {AND} {RELATED} {AREAS}},
	volume = {24},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0266-4666, 1469-4360},
	shorttitle = {{GUEST} {EDITORS}' {EDITORIAL}},
	url = {https://www.cambridge.org/core/product/identifier/S0266466608080134/type/journal_article},
	doi = {10.1017/S0266466608080134},
	abstract = {Model selection procedures have become an integral part of almost any statistical or econometric analysis of data. Prominent examples include the selection of explanatory variables in (non)linear regression or lag-length selection in time series models. It is safe to say that these methods have become an integral part of the toolbox of modern data analysis. Moreover, research on model selection (or related procedures such as model averaging and shrinkage procedures) and its implications for statistical analysis has intensified in recent years. This is witnessed by the fact that it is difficult to pick up any recent issue of an econometrics or statistics journal and avoid encountering a paper where some form of model selection, or model averaging, or general shrinkage estimation is considered.},
	language = {en},
	number = {2},
	urldate = {2025-12-04},
	journal = {Econometric Theory},
	author = {Leeb, Hannes and Pötscher, Benedikt M.},
	month = apr,
	year = {2008},
	keywords = {Survey},
	pages = {319--322},
	file = {Leeb and Pötscher - 2008 - GUEST EDITORS' EDITORIAL RECENT DEVELOPMENTS IN MODEL SELECTION AND RELATED AREAS.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Leeb and Pötscher - 2008 - GUEST EDITORS' EDITORIAL RECENT DEVELOPMENTS IN MODEL SELECTION AND RELATED AREAS.pdf:application/pdf},
}
@article{chernozhukov_doubledebiasedneyman_2017,
	title = {Double/{Debiased}/{Neyman} {Machine} {Learning} of {Treatment} {Effects}},
	volume = {107},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.p20171038},
	doi = {10.1257/aer.p20171038},
	abstract = {Chernozhukov et al. (2016) provide a generic double/de-biased machine learning (ML) approach for obtaining valid inferential statements about focal parameters, using Neyman-orthogonal scores and cross-fitting, in settings where nuisance parameters are estimated using ML methods. In this note, we illustrate the application of this method in the context of estimating average treatment effects and average treatment effects on the treated using observational data.},
	language = {en},
	number = {5},
	urldate = {2025-12-02},
	journal = {American Economic Review},
	author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney},
	month = may,
	year = {2017},
	keywords = {AI/ML in Econ, Survey},
	pages = {261--265},
	file = {Chernozhukov et al. - 2017 - DoubleDebiasedNeyman Machine Learning of Treatment Effects.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Chernozhukov et al. - 2017 - DoubleDebiasedNeyman Machine Learning of Treatment Effects.pdf:application/pdf},
}

@article{belloni_program_2017,
	title = {Program {Evaluation} and {Causal} {Inference} {With} {High}-{Dimensional} {Data}},
	volume = {85},
	issn = {0012-9682},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA12723},
	doi = {10.3982/ECTA12723},
	abstract = {In this paper, we provide efficient estimators and honest confidence bands for a variety of treatment effects including local average (LATE) and local quantile treatment effects (LQTE) in data-rich environments. We can handle very many control variables, endogenous receipt of treatment, heterogeneous treatment effects, and function-valued outcomes. Our framework covers the special case of exogenous receipt of treatment, either conditional on controls or unconditionally as in randomized control trials. In the latter case, our approach produces efﬁcient estimators and honest bands for (functional) average treatment effects (ATE) and quantile treatment effects (QTE). To make informative inference possible, we assume that key reduced-form predictive relationships are approximately sparse. This assumption allows the use of regularization and selection methods to estimate those relations, and we provide methods for postregularization and post-selection inference that are uniformly valid (honest) across a wide range of models. We show that a key ingredient enabling honest inference is the use of orthogonal or doubly robust moment conditions in estimating certain reducedform functional parameters. We illustrate the use of the proposed methods with an application to estimating the effect of 401(k) eligibility and participation on accumulated assets. The results on program evaluation are obtained as a consequence of more general results on honest inference in a general moment-condition framework, which arises from structural equation models in econometrics. Here, too, the crucial ingredient is the use of orthogonal moment conditions, which can be constructed from the initial moment conditions. We provide results on honest inference for (function-valued) parameters within this general framework where any high-quality, machine learning methods (e.g., boosted trees, deep neural networks, random forest, and their aggregated and hybrid versions) can be used to learn the nonparametric/high-dimensional components of the model. These include a number of supporting auxiliary results that are of major independent interest: namely, we (1) prove uniform validity of a multiplier bootstrap, (2) offer a uniformly valid functional delta method, and (3) provide results for sparsitybased estimation of regression functions for function-valued outcomes.},
	language = {en},
	number = {1},
	urldate = {2025-12-04},
	journal = {Econometrica},
	author = {Belloni, Alexandre and Chernozhukov, Victor and Fernandez-Val, Iván and Hansen, Christian},
	year = {2017},
	keywords = {AI/ML in Econ},
	pages = {233--298},
	file = {Belloni et al. - 2017 - Program Evaluation and Causal Inference With High-Dimensional Data.pdf:/Users/raul/Library/CloudStorage/GoogleDrive-raul.guarini@gmail.com/My Drive/Zotero Attachments/Belloni et al. - 2017 - Program Evaluation and Causal Inference With High-Dimensional Data.pdf:application/pdf},
}


